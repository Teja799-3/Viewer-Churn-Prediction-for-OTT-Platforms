{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51a5caef-ae16-408f-be0a-1155ad23d377",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# USE CASE 1: Predictive Churn Model Development (MLlib)\n",
    "# Project: Viewer Churn Prediction for OTT Platforms\n",
    "# Platform: Databricks (Free Edition)\n",
    "# Author: Erugurala Teja (24MBMB19)\n",
    "# =====================================================\n",
    "\n",
    "# Step 1️⃣: Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, length, regexp_replace, lower\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e121554-69fc-4870-8beb-fa47fc95a9cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2️⃣: Import Required Libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, length, regexp_replace, lower\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac974ec5-d691-4da5-b721-e0687345620c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 3️⃣: Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"OTT_Churn_Model\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9336da33-4c85-403c-afe6-01b4bf014f6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully loaded!\nTotal Records: 6000\nroot\n |-- app_name: string (nullable = true)\n |-- reviewId: string (nullable = true)\n |-- userName: string (nullable = true)\n |-- content: string (nullable = true)\n |-- score: string (nullable = true)\n |-- at: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Step 4️⃣: Load the Dataset\n",
    "# Ensure your file exists in the mentioned path\n",
    "data_path = \"/Volumes/workspace/default/dataset/ott_reviews.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "print(\"✅ Data successfully loaded!\")\n",
    "print(f\"Total Records: {df.count()}\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1325256e-6124-4ad5-b2ef-4d1287342031",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data cleaned successfully — sample records:\n+--------+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|app_name|score               |content                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n+--------+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|Netflix |5                   |am sure netflix is a very good app                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n|Netflix |1                   |nothing worth watching waste of money                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|Netflix |1                   |i had an issue related to video quality of the app but the representative didn t even bother to tell me her name and told me to contact my isp  i mean what  every other thing is working just fine  all the other ott apps on my phone and everybody s phone in my house  i m the only one who used netflix  now i ve uninstall it obviously and ended the subscription  tell your customer care people to give their names to people so people can address them  and fix bugs in your app  instead of blaming isp |\n|Netflix | very inconvenient.\"| it s annoying that i cannot watch continuously without having to reset my phonebecause of the          error                                                                                                                                                                                                                                                                                                                                                                                                       |\n|Netflix |1                   |oct      s update  doesn t even allow users to open netflix  wont go past the splashscreen  aug      update  no longer enables control over literal video resolution i m for sure canceling if this doesn t get fixed                                                                                                                                                                                                                                                                                               |\n+--------+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Step 5️⃣: Basic Data Cleaning\n",
    "# Remove null/empty reviews, clean special characters, and lowercase\n",
    "df_clean = df.dropna(subset=[\"content\", \"score\"])\n",
    "df_clean = df_clean.withColumn(\"content\", regexp_replace(\"content\", \"[^a-zA-Z ]\", \" \"))\n",
    "df_clean = df_clean.withColumn(\"content\", lower(col(\"content\")))\n",
    "df_clean = df_clean.filter(length(col(\"content\")) > 20)\n",
    "\n",
    "print(\"✅ Data cleaned successfully — sample records:\")\n",
    "df_clean.select(\"app_name\", \"score\", \"content\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca363aa3-6a5a-471d-b1e5-1c8d680455cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Score column successfully converted to numeric!\n+--------+-----+---------+\n|app_name|score|score_num|\n+--------+-----+---------+\n| Netflix|    5|      5.0|\n| Netflix|    1|      1.0|\n| Netflix|    1|      1.0|\n| Netflix|    1|      1.0|\n| Netflix|    5|      5.0|\n+--------+-----+---------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, expr\n",
    "\n",
    "# Step 6️⃣: Ensure 'score' column is numeric (safe casting)\n",
    "# Some values might be text; we use try_cast to handle that gracefully\n",
    "df_fixed = df_clean.withColumn(\"score_num\", expr(\"try_cast(score as double)\"))\n",
    "\n",
    "# Drop rows where score cannot be converted to a number\n",
    "df_fixed = df_fixed.dropna(subset=[\"score_num\"])\n",
    "\n",
    "print(\"✅ Score column successfully converted to numeric!\")\n",
    "df_fixed.select(\"app_name\", \"score\", \"score_num\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "811a3853-6562-46f3-a310-ad695c6ea31c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Target variable 'churn_label' created successfully!\n+--------+---------+-----------+\n|app_name|score_num|churn_label|\n+--------+---------+-----------+\n| Netflix|      5.0|          0|\n| Netflix|      1.0|          1|\n| Netflix|      1.0|          1|\n| Netflix|      1.0|          1|\n| Netflix|      5.0|          0|\n+--------+---------+-----------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Step 7️⃣: Create Target Variable (Churn Label)\n",
    "# Logic: score <= 2 → likely churn, score >= 4 → retained\n",
    "df_labeled = df_fixed.withColumn(\n",
    "    \"churn_label\",\n",
    "    when(col(\"score_num\") <= 2, 1).when(col(\"score_num\") >= 4, 0).otherwise(None)\n",
    ").dropna(subset=[\"churn_label\"])\n",
    "\n",
    "print(\"✅ Target variable 'churn_label' created successfully!\")\n",
    "df_labeled.select(\"app_name\", \"score_num\", \"churn_label\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a9b705f-d153-4fed-8486-534cc4e5f400",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# CONTINUE PIPELINE — TEXT PREPROCESSING & MODELING\n",
    "# =====================================================\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ac71ed-3f2d-4b11-8dfb-78a4059afae3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 8️⃣: Text Preprocessing Pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"content\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"rawFeatures\", numFeatures=2000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49bd862a-0246-4bcb-9e37-ba71d1a13fc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 9️⃣: Model Definition (Logistic Regression)\n",
    "lr = LogisticRegression(labelCol=\"churn_label\", featuresCol=\"features\", maxIter=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c11b5d56-db5f-498d-8e8c-718807bd2067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step \uD83D\uDD1F: Create Pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, tf, idf, lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "429941aa-c67c-4adc-b02b-55fe07a6922d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data split completed — Train: 2321, Test: 568\n"
     ]
    }
   ],
   "source": [
    "# Step 1️⃣1️⃣: Split Data (Train/Test)\n",
    "train_df, test_df = df_labeled.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"✅ Data split completed — Train: {train_df.count()}, Test: {test_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81883925-dd99-421e-9867-a6f00309dee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 1️⃣2️⃣: Train Model\n",
    "model = pipeline.fit(train_df)\n",
    "print(\"✅ Model training completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b73a3cd-2a23-49e7-9795-d431af0e227e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predictions generated successfully — preview:\n+------------------+---------+-----------+-------------------------------------------+----------+\n|app_name          |score_num|churn_label|probability                                |prediction|\n+------------------+---------+-----------+-------------------------------------------+----------+\n|Amazon Prime Video|2.0      |1          |[0.4195849417861692,0.5804150582138308]    |1.0       |\n|Amazon Prime Video|1.0      |1          |[1.8150127631962167E-6,0.9999981849872368] |1.0       |\n|Amazon Prime Video|1.0      |1          |[8.106512443979171E-8,0.9999999189348756]  |1.0       |\n|Amazon Prime Video|1.0      |1          |[7.555650576944076E-7,0.9999992444349423]  |1.0       |\n|Amazon Prime Video|1.0      |1          |[3.3558786676488055E-10,0.9999999996644121]|1.0       |\n+------------------+---------+-----------+-------------------------------------------+----------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Step 1️⃣3️⃣: Generate Predictions\n",
    "predictions = model.transform(test_df)\n",
    "print(\"✅ Predictions generated successfully — preview:\")\n",
    "predictions.select(\"app_name\", \"score_num\", \"churn_label\", \"probability\", \"prediction\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b5a4bc8-7968-402f-8aee-db6bdd74bd06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA Model Evaluation Completed — AUC Score: 0.797\n"
     ]
    }
   ],
   "source": [
    "# Step 1️⃣4️⃣: Evaluate Model Performance\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"churn_label\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"\uD83D\uDCCA Model Evaluation Completed — AUC Score: {auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caeb75bf-19c9-481a-8c48-d449742e3f2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n\uD83D\uDCC8 HUMANIZED OUTPUT SUMMARY\nTotal Evaluated Reviews: 568\nPredicted Churned Users : 423\nPredicted Retained Users: 145\nChurn Ratio: 74.47%\nModel Accuracy (AUC): 0.80\n===============================================\n"
     ]
    }
   ],
   "source": [
    "# Step 1️⃣5️⃣: Humanized Output Summary\n",
    "total = predictions.count()\n",
    "churned = predictions.filter(col(\"prediction\") == 1).count()\n",
    "retained = predictions.filter(col(\"prediction\") == 0).count()\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"\uD83D\uDCC8 HUMANIZED OUTPUT SUMMARY\")\n",
    "print(f\"Total Evaluated Reviews: {total}\")\n",
    "print(f\"Predicted Churned Users : {churned}\")\n",
    "print(f\"Predicted Retained Users: {retained}\")\n",
    "print(f\"Churn Ratio: {(churned / total * 100):.2f}%\")\n",
    "print(f\"Model Accuracy (AUC): {auc:.2f}\")\n",
    "print(\"===============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a440bc27-7e52-4e68-9424-08471f8d83fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predictions saved successfully to: /Volumes/workspace/default/dataset/ott_churn_predictions\n\uD83D\uDCC2 Download from: Databricks → Data → Volumes → workspace → default → dataset → ott_churn_predictions\n"
     ]
    }
   ],
   "source": [
    "# Step 1️⃣6️⃣: Save Predictions to CSV (Downloadable)\n",
    "output_path = \"/Volumes/workspace/default/dataset/ott_churn_predictions\"\n",
    "predictions.select(\n",
    "    \"app_name\", \"userName\", \"score_num\", \"content\", \"churn_label\", \"prediction\"\n",
    ").coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(output_path)\n",
    "\n",
    "print(f\"✅ Predictions saved successfully to: {output_path}\")\n",
    "print(\"\uD83D\uDCC2 Download from: Databricks → Data → Volumes → workspace → default → dataset → ott_churn_predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "243b237e-ea0f-414d-8d0c-186255e44447",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Use Case-1 Predictive Churn Model Development",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}